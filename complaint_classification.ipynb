{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5c2cf1-ed6e-4ae2-9422-bbd5edb4b746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/7xrb2yxn02xbxqqj_4r57rnw0000gn/T/ipykernel_4225/2916043767.py:5: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"consumer_complaints.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Consumer complaint narrative  category\n",
      "299  I have dealt with XXXX XXXX all my life and ev...         1\n",
      "321  I am writing to address a concerning matter re...         1\n",
      "377  This is so annoying & frustrating. Ive sent Ex...         1\n",
      "378  Delete those late dates and update the statuse...         1\n",
      "380  This is so annoying & frustrating. Ive sent Eq...         1\n"
     ]
    }
   ],
   "source": [
    "#Load the Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"consumer_complaints.csv\")\n",
    "\n",
    "# Keep only necessary columns\n",
    "df = df[[\"Consumer complaint narrative\", \"Product\"]].dropna()\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    \"Credit reporting, repair, or other\": 0,\n",
    "    \"Debt collection\": 1,\n",
    "    \"Consumer Loan\": 2,\n",
    "    \"Payday loan, title loan, personal loan, or advance\": 2,\n",
    "    \"Mortgage\": 3\n",
    "}\n",
    "\n",
    "# Filter dataset to keep only relevant categories\n",
    "df = df[df[\"Product\"].isin(category_mapping.keys())]\n",
    "\n",
    "# Apply category mapping\n",
    "df[\"category\"] = df[\"Product\"].map(category_mapping)\n",
    "\n",
    "# Drop the original \"Product\" column\n",
    "df = df.drop(columns=[\"Product\"])\n",
    "\n",
    "# Check if data is loaded properly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f528426-4d57-400c-97ef-16e125296cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/surya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/surya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/surya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category                                       cleaned_text\n",
      "299         1  dealt xxxx xxxx life even though put fraud ale...\n",
      "321         1  writing address concerning matter regarding cr...\n",
      "377         1  annoying frustrating ive sent experian multipl...\n",
      "378         1  delete late date update status account mention...\n",
      "380         1  annoying frustrating ive sent equifax multiple...\n"
     ]
    }
   ],
   "source": [
    "#Text Preprocessing (Cleaning the Text)\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define text cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = re.sub(r'\\W+', ' ', text)  \n",
    "    words = word_tokenize(text)  \n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  \n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply text cleaning\n",
    "df[\"cleaned_text\"] = df[\"Consumer complaint narrative\"].astype(str).apply(clean_text)\n",
    "\n",
    "# Drop the original text column\n",
    "df = df.drop(columns=[\"Consumer complaint narrative\"])\n",
    "\n",
    "# Check cleaned text\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96dbf1c-0f9d-46ea-8c37-8a4e5f770f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (439589, 5000)\n"
     ]
    }
   ],
   "source": [
    "##Convert Text into Numerical Features (TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Use top 5000 words\n",
    "\n",
    "# Convert text into numerical form\n",
    "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
    "\n",
    "# Store the target labels (categories)\n",
    "y = df[\"category\"]\n",
    "\n",
    "print(\"TF-IDF Matrix Shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ffced54-82e7-4f68-ba2d-b26a786f9a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667644850883778\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.98      0.98     61160\n",
      "           2       0.76      0.50      0.61      1821\n",
      "           3       0.96      0.96      0.96     24937\n",
      "\n",
      "    accuracy                           0.97     87918\n",
      "   macro avg       0.90      0.82      0.85     87918\n",
      "weighted avg       0.97      0.97      0.97     87918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the Machine Learning Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7f5c0f-6f14-421b-959e-dd850d37ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: 3\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions on New Complaints\n",
    "# Define a new complaint\n",
    "new_complaint = [\"I am unable to pay my mortgage due to a system error.\"]\n",
    "\n",
    "# Clean the complaint\n",
    "new_complaint_cleaned = [clean_text(text) for text in new_complaint]\n",
    "\n",
    "# Convert it to TF-IDF format\n",
    "new_complaint_vectorized = vectorizer.transform(new_complaint_cleaned)\n",
    "\n",
    "# Predict category\n",
    "predicted_category = model.predict(new_complaint_vectorized)\n",
    "print(\"Predicted Category:\", predicted_category[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e7c8e-d333-434b-8a73-61cdea8a414d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
